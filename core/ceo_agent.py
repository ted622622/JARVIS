"""CEO Agent â€” top-level dispatcher for J.A.R.V.I.S.

Responsibilities:
- Parse user intent and dispatch to appropriate workers
- Emotion detection â†’ empathetic response path
- Inject SOUL.md persona into all interactions
- Skill invocation via SkillRegistry (Task 8.3)
- Proactive web search: detect need â†’ fetch â†’ inject into context
- Reactive tool-use: LLM can invoke [FETCH:url] / [SEARCH:query] as fallback
- Memory integration for context continuity
"""

from __future__ import annotations

import asyncio
import json
import re
import time
from datetime import datetime
from pathlib import Path
from typing import Any
from urllib.parse import quote_plus

from loguru import logger

try:
    from opencc import OpenCC
    _s2t = OpenCC("s2t")
except ImportError:
    _s2t = None
    logger.warning("OpenCC not installed â€” Clawra s2t filter disabled")

from clients.base_client import ChatMessage, ChatResponse
from core.model_router import ModelRole, ModelRouter, RouterError
from core.conversation_compressor import ConversationCompressor
from core.help_decision import HelpDecisionEngine
from core.react_executor import ReactExecutor, FuseState, TaskResult
from core.security_gate import OperationType, OperationVerdict
from core.shared_memory import SharedMemory
from core.soul_growth import SoulGrowth
from core.task_router import TaskRouter

# â”€â”€ Phase 2: Agent SDK complexity classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TaskComplexity:
    SIMPLE = "simple"
    MEDIUM = "medium"
    COMPLEX = "complex"


_COMPLEX_PATTERNS = re.compile(
    r"å¹«æˆ‘è¨‚|å¹«æˆ‘é ç´„|å¹«æˆ‘å®‰æ’|"
    r"å¹«æˆ‘ç ”ç©¶|å¹«æˆ‘åˆ†æ|å¹«æˆ‘æ¯”è¼ƒ|"
    r"å¹«æˆ‘å¯«ä¸€[ä»½ç¯‡å°]|å¹«æˆ‘æ•´ç†|"
    r"åšä¸€å€‹.*è¨ˆç•«|è¦åŠƒ.*è¡Œç¨‹|"
    r"æŸ¥.*ç„¶å¾Œ.*æ•´ç†|æœ.*ç„¶å¾Œ.*æ¯”è¼ƒ|"
    r"æ­¥é©Ÿ|æµç¨‹|å®Œæ•´",
    re.IGNORECASE,
)

_SIMPLE_PATTERNS = re.compile(
    r"^(ä½ å¥½|å—¨|hi|hello|æ—©å®‰|æ™šå®‰|åœ¨å—|å¹¹å˜›|"
    r"è¬è¬|å¥½çš„|OK|å—¯|å“ˆå“ˆ|æ¬¸|å–”|å°|æ˜¯)",
    re.IGNORECASE,
)

# Pattern for LLM tool calls in response text (fallback)
_TOOL_PATTERN = re.compile(r'\[(?:FETCH|SEARCH|MAPS):([^\]]+)\]')

# â”€â”€ Patch O: Long-task detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_LONG_TASK_TYPES = frozenset({"web_search", "web_browse", "restaurant_booking", "code"})
_URL_PATTERN = re.compile(r"https?://\S+")

# â”€â”€ Web content truncation limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_FETCH_CHAR_LIMIT = 50_000   # URL fetch: enough for READMEs / full pages
_SEARCH_CHAR_LIMIT = 3_000   # DuckDuckGo: search results are short

# â”€â”€ Patch P: Long-content chunking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_LONG_CONTENT_THRESHOLD = 2000     # ç”¨æˆ¶è¨Šæ¯å­—æ•¸è§¸ç™¼ï¼ˆæ­é…åˆ†æé—œéµå­—ï¼‰
_STRUCTURED_THRESHOLD = 500        # çµæ§‹åŒ–å…§å®¹é–€æª»ï¼ˆæ­é… MD æ¨™è¨˜ï¼‰
_LONG_WEB_THRESHOLD = 5000         # ç¶²é å…§å®¹å­—æ•¸è§¸ç™¼
_CHUNK_SIZE = 3000                 # æ¯æ®µå¤§å°ï¼ˆåŒ TranscribeWorkerï¼‰
_ANALYSIS_KEYWORDS = re.compile(r"æ•´ç†|æ‘˜è¦|æå–|åˆ†æ|æ¯”è¼ƒ|æ­¸ç´|çµ±æ•´|å°ç…§")
_STRUCTURED_MARKERS = re.compile(r"^#{1,4}\s|^>\s|^---$|^```|^\- \[", re.MULTILINE)
# Task template placeholders â€” these need CEO tool-use ([FETCH:], [SEARCH:]), not chunking
_TASK_TEMPLATE_PATTERN = re.compile(r"ï¼ˆ[^ï¼‰]*å…§å®¹[^ï¼‰]*ï¼‰|ï¼ˆ[^ï¼‰]*å¡«å…¥[^ï¼‰]*ï¼‰|\{\{.+?\}\}")
# GitHub repo references: owner/repo patterns (for proactive fetch in task templates)
_GITHUB_REPO_PATTERN = re.compile(r'\b([A-Za-z][\w.-]+/[A-Za-z][\w.-]+)\b')

# â”€â”€ LLM reply cleanup (strip leaked thinking tags) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_THINK_TAG_PATTERN = re.compile(r"</?think>", re.IGNORECASE)
_THINK_BLOCK_PATTERN = re.compile(r"<think>.*?</think>", re.DOTALL | re.IGNORECASE)
_WRAPPING_CODE_BLOCK = re.compile(r"^```(?:\w*)\n?(.*?)```$", re.DOTALL)


def _clean_llm_reply(text: str) -> str:
    """Strip leaked thinking tags and wrapping code blocks from LLM output."""
    if not text:
        return text
    # Remove full <think>...</think> blocks first
    text = _THINK_BLOCK_PATTERN.sub("", text)
    # Remove stray </think> or <think> tags
    text = _THINK_TAG_PATTERN.sub("", text)
    # Remove wrapping code blocks (```...\ncontent\n```)
    text = text.strip()
    m = _WRAPPING_CODE_BLOCK.match(text)
    if m:
        text = m.group(1).strip()
    return text.strip()


def _force_traditional_chinese(text: str) -> str:
    """Convert any leaked simplified Chinese to traditional Chinese."""
    if not text or _s2t is None:
        return text
    return _s2t.convert(text)


# â”€â”€ H1 v2: Task Resolution Chains â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI/API first â†’ httpx â†’ browser (last resort) â†’ partial assist
# Each chain entry: {"method": str, "worker": str, "timeout": int}
TASK_RESOLUTION_CHAINS: dict[str, dict] = {
    # â”€â”€ Calendar / Email â€” gog CLI handles it â”€â”€
    "calendar": {
        "chain": [
            {"method": "gog_cli", "worker": "gog", "timeout": 15},
        ],
    },
    "email": {
        "chain": [
            {"method": "gog_cli", "worker": "gog", "timeout": 15},
        ],
    },
    # â”€â”€ Booking â€” API first, browser last â”€â”€
    "booking": {
        "chain": [
            {"method": "httpx_search", "worker": "browser", "timeout": 15},
            {"method": "browser", "worker": "browser", "timeout": 45},
            {"method": "partial_assist", "worker": "knowledge", "timeout": 30},
        ],
    },
    # â”€â”€ Web search â€” httpx â†’ browser â†’ knowledge â”€â”€
    "web_search": {
        "chain": [
            {"method": "httpx_search", "worker": "browser", "timeout": 15},
            {"method": "browser_search", "worker": "browser", "timeout": 30},
            {"method": "knowledge_reply", "worker": "knowledge", "timeout": 30},
        ],
    },
    # â”€â”€ Code â”€â”€
    "code_task": {
        "chain": [
            {"method": "direct", "worker": "code", "timeout": 60},
            {"method": "knowledge_reply", "worker": "knowledge", "timeout": 30},
        ],
    },
    # â”€â”€ General fallback â”€â”€
    "general": {
        "chain": [
            {"method": "knowledge_reply", "worker": "knowledge", "timeout": 30},
        ],
    },
}

# â”€â”€ Proactive web search detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Patterns that indicate user needs web information
_WEB_NEED_PATTERNS = re.compile(
    r"å¹«æˆ‘æŸ¥|å¹«æˆ‘æœ|å¹«æˆ‘æ‰¾|æŸ¥ä¸€ä¸‹|æœä¸€ä¸‹|æœå°‹|æœç´¢|æŸ¥è©¢|"
    r"å¹«æˆ‘è¨‚|è¨‚ä½|é ç´„|é å®š|booking|reserve|"
    r"ä¸Šç¶².*?(?:æŸ¥|çœ‹|æœ|æ‰¾)|é€£å¤–ç¶²|é€£ç¶²è·¯|"
    r"(?:ä»Šå¤©|ä»Šæ—¥|ç¾åœ¨|ç›®å‰|æœ€æ–°|æœ€è¿‘).*?(?:å¤©æ°£|æ–°è|æ¶ˆæ¯|è¡Œæƒ…|åƒ¹æ ¼|å ±å°)|"
    r"(?:å¤©æ°£|æ–°è|è¡Œæƒ…).*?(?:æ€[éº¼æ¨£]|å¦‚ä½•|å¤šå°‘|ä»€éº¼)|"
    r"(?:è‚¡åƒ¹|åŒ¯ç‡|æ¯”ç‰¹å¹£|bitcoin|btc|eth|åŠ å¯†è²¨å¹£).*?(?:å¤šå°‘|ç¾åœ¨|ä»Šå¤©|å¹¾|æ¼²|è·Œ)?|"
    r"å¤šå°‘éŒ¢|å“ªè£¡è²·|æ€éº¼å»|å¹¾é».*?(?:é–‹|é—œ|ç‡Ÿæ¥­)|"
    r"https?://\S+",
    re.IGNORECASE,
)

# Extract URL from user message for direct fetch
_URL_IN_MSG = re.compile(r'(https?://\S+)')

# Prefixes to strip when extracting search query
_SEARCH_PREFIX = re.compile(
    r"^(?:å¹«æˆ‘|è«‹ä½ ?|éº»ç…©)?(?:æŸ¥ä¸€ä¸‹|æœä¸€ä¸‹|æœå°‹|æœç´¢|æŸ¥è©¢|æŸ¥|æœ|æ‰¾|çœ‹ä¸€ä¸‹|çœ‹çœ‹)\s*",
)


class CEOAgent:
    """Central orchestrator â€” all user interactions flow through here.

    Usage:
        ceo = CEOAgent(
            model_router=router,
            soul=soul,
            emotion_classifier=emotion,
            memos=memos,
            skill_registry=registry,
            security_gate=security,
        )
        response = await ceo.handle_message("å¹«æˆ‘æŸ¥ä¸€ä¸‹æ˜å¤©è¡Œç¨‹")
    """

    def __init__(
        self,
        model_router: ModelRouter,
        soul: Any = None,
        emotion_classifier: Any = None,
        memos: Any = None,
        skill_registry: Any = None,
        security_gate: Any = None,
        workers: dict[str, Any] | None = None,
        markdown_memory: Any = None,
    ):
        self.router = model_router
        self.soul = soul
        self.emotion = emotion_classifier
        self.memos = memos
        self.skills = skill_registry
        self.security = security_gate
        self.workers = workers or {}
        self.md_memory = markdown_memory
        self.memory_search: Any = None  # G6: set externally
        self.pending: Any = None  # H4: PendingTaskManager, set externally
        self._react: ReactExecutor | None = None
        self._fuse = FuseState()
        self._post_action: Any = None  # K2: PostActionChain
        self._persona = "jarvis"
        self._session_id = "default"
        self._last_skill_failure: str | None = None
        self._silent_until: float = 0.0  # Patch D: humanized silent mode
        # G4: Session transcript tracking
        self._session_transcript: list[tuple[str, str, str]] = []  # (role, persona, text)
        self._last_message_time: float = 0.0
        self._session_idle_timeout = 300  # 5 minutes
        # G2: Memory flush tracking
        self._turn_count = 0
        self._flush_threshold = 20  # flush every 20 turns
        # Patch I: multi-task modules
        self._compressor = ConversationCompressor()
        self._compressor.set_pre_flush_callback(self._pre_flush_extract)
        self._task_router = TaskRouter()
        self._help_engine = HelpDecisionEngine()
        # Patch J: soul evolution
        self._soul_growth: SoulGrowth | None = None
        self._shared_memory: SharedMemory | None = None
        # Phase 2: Agent SDK executor (lazy-init)
        self._agent_executor: Any = None
        # Emotion passthrough for voice TTS
        self._last_emotion: str = "normal"

    # â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def handle_message(
        self,
        user_message: str,
        *,
        persona: str | None = None,
        context: dict[str, Any] | None = None,
    ) -> str | dict[str, Any]:
        """Process a user message end-to-end.

        Steps:
        1. Classify emotion
        2. Check if a skill can handle it
        3. Build system prompt with persona + context
        4. Route to CEO model
        5. Store conversation in MemOS

        Returns:
            str â€” plain text reply
            dict â€” rich reply, e.g. {"text": "...", "photo_url": "..."}
        """
        active_persona = persona or self._persona
        session_id = f"{active_persona}_{self._session_id}"

        # Silent mode check (Patch D)
        now = time.time()
        if now < self._silent_until:
            await self._store_conversation(user_message, "[éœé»˜ä¸­ï¼Œç¨å¾Œå›è¦†]", session_id)
            if active_persona == "clawra":
                return "å—¯...æˆ‘ç¾åœ¨æœ‰é»ç´¯ï¼Œç­‰æˆ‘ä¸€ä¸‹ä¸‹å–”"
            return "Sir, ç³»çµ±æ­£åœ¨çŸ­æš«ä¼‘æ¯ä¸­ï¼Œç¨å¾Œæ¢å¾©æœå‹™ã€‚"

        # Was silent but now recovered â€” send welcome back
        was_silent = self._silent_until > 0
        if was_silent:
            self._silent_until = 0.0
            logger.info("Silent mode ended, resuming normal operation")

        try:
            result = await self._process_message(
                user_message, active_persona, session_id, context, was_silent,
            )
        except RouterError:
            # All providers down â€” enter silent mode
            self._silent_until = time.time() + 900  # 15 min
            logger.warning("All providers down, entering silent mode for 15 min")
            await self._store_conversation(user_message, "[ç³»çµ±é€²å…¥éœé»˜æ¨¡å¼]", session_id)
            if active_persona == "clawra":
                return "æ¬¸...æˆ‘æœ‰é»ç´¯äº†ï¼Œè®“æˆ‘ä¼‘æ¯ä¸€ä¸‹ä¸‹å¥½å—ï¼Ÿå¤§æ¦‚ 15 åˆ†é˜å¾Œå›ä¾†æ‰¾ä½  ğŸ’¤"
            return "Sir, ç³»çµ±éœ€è¦çŸ­æš«ä¼‘æ¯ã€‚é è¨ˆ 15 åˆ†é˜å¾Œæ¢å¾©ï¼Œå±†æ™‚æˆ‘æœƒä¸»å‹•é€šçŸ¥æ‚¨ã€‚"

        # Clawra: force simplified â†’ traditional Chinese conversion
        if active_persona == "clawra" and _s2t is not None:
            if isinstance(result, dict):
                if "text" in result and isinstance(result["text"], str):
                    result["text"] = _force_traditional_chinese(result["text"])
            elif isinstance(result, str):
                result = _force_traditional_chinese(result)

        return result

    # â”€â”€ Phase 2: Agent SDK helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _classify_complexity(self, message: str) -> str:
        """Classify message complexity for Agent SDK routing."""
        if len(message) < 10:
            return TaskComplexity.SIMPLE
        if _SIMPLE_PATTERNS.match(message):
            return TaskComplexity.SIMPLE
        if _COMPLEX_PATTERNS.search(message):
            return TaskComplexity.COMPLEX
        if _WEB_NEED_PATTERNS.search(message):
            return TaskComplexity.MEDIUM
        return TaskComplexity.SIMPLE

    def _get_agent_executor(self) -> Any:
        """Lazy-init AgentExecutor."""
        if self._agent_executor is None:
            try:
                from core.agent_executor import AgentExecutor
                self._agent_executor = AgentExecutor(
                    jarvis_root=str(Path(__file__).parent.parent)
                )
            except ImportError:
                logger.warning("claude-agent-sdk not installed, Agent SDK disabled")
                return None
        return self._agent_executor

    async def _process_message(
        self,
        user_message: str,
        active_persona: str,
        session_id: str,
        context: dict[str, Any] | None,
        was_silent: bool,
    ) -> str | dict[str, Any]:
        """Core message processing (extracted for silent mode error handling)."""
        # I3: Track conversation in compressor
        self._compressor.add_turn("user", user_message)

        # 1. Emotion detection
        emotion_label = "normal"
        if self.emotion:
            emotion_label = await self.emotion.classify(user_message)
            logger.debug(f"Emotion: {emotion_label}")

        # 2. Check skill registry for matching skill
        skill_result = await self._try_skill_match(user_message, active_persona, session_id)
        if skill_result is not None:
            return skill_result

        # 2b. G2: Memory flush â€” check if we should flush before context gets too long
        self._turn_count += 1
        if self._turn_count >= self._flush_threshold and self.md_memory:
            await self._memory_flush(active_persona, session_id)
            self._turn_count = 0

        # 2c. Check if previous session should be saved (5 min idle)
        now = time.time()
        if (
            self._last_message_time > 0
            and now - self._last_message_time > self._session_idle_timeout
            and self._session_transcript
        ):
            await self._save_session_transcript(active_persona)
        self._last_message_time = now

        # 2c. Memory search â€” inject relevant context (supports async HybridSearch)
        extra_ctx = dict(context) if context else {}
        if self.memory_search:
            try:
                search_fn = getattr(self.memory_search, "search", None)
                if asyncio.iscoroutinefunction(search_fn):
                    results = await self.memory_search.search(user_message, top_k=3)
                else:
                    results = self.memory_search.search(user_message, top_k=3)
                if results:
                    mem_ctx = "\n".join(r["text"][:200] for r in results)
                    extra_ctx["ç›¸é—œè¨˜æ†¶"] = mem_ctx
            except Exception as e:
                logger.debug(f"Memory search failed: {e}")

        # 2.5 Phase 2: Agent SDK dispatch for COMPLEX tasks
        complexity = self._classify_complexity(user_message)
        if complexity == TaskComplexity.COMPLEX:
            executor = self._get_agent_executor()
            if executor is not None:
                logger.info("Task COMPLEX â†’ Agent SDK dispatch")
                mem_ctx = extra_ctx.get("ç›¸é—œè¨˜æ†¶", "")
                try:
                    sdk_result = await executor.run(
                        task=user_message,
                        tier="complex",
                        persona=active_persona,
                        extra_context=mem_ctx,
                    )
                    if sdk_result["success"]:
                        reply = sdk_result["response"]
                        await self._store_conversation(
                            user_message, reply, session_id,
                        )
                        self._compressor.add_turn("assistant", reply)
                        logger.info(
                            f"Agent SDK success: {sdk_result['tool_calls']} tools, "
                            f"{sdk_result['duration']}s"
                        )
                        # 80% quota warning
                        if executor.is_quota_low():
                            usage = executor.get_daily_usage()
                            logger.warning(
                                f"Agent SDK quota alert: "
                                f"{usage['usage_pct']}% used "
                                f"({usage['daily_tokens']:,}/{usage['daily_limit']:,})"
                            )
                            # Append warning to reply so TG user sees it
                            reply += (
                                f"\n\nâš ï¸ Agent SDK é¡åº¦: "
                                f"{usage['usage_pct']}% å·²ä½¿ç”¨"
                            )
                        # Extract phone/url for TG separate messages
                        phone = self._extract_phone(reply)
                        booking_url = self._extract_booking_url(reply)
                        if phone or booking_url:
                            return {
                                "text": reply,
                                "phone": phone,
                                "booking_url": booking_url,
                            }
                        return reply
                except Exception as e:
                    logger.warning(f"Agent SDK failed: {e}, falling back")

        # 2d. Proactive web search â€” detect need and fetch BEFORE LLM responds
        web_results = await self._proactive_web_search(user_message)
        _booking_phone = None
        _booking_url = None
        if web_results:
            _WEB_CTX_PREFIX = (
                "ï¼ˆä»¥ä¸‹æ˜¯ç³»çµ±å·²æŠ“å–çš„ç¶²é å…§å®¹ï¼Œè«‹ç›´æ¥åˆ†ææ­¤æ–‡å­—å›ç­”ç”¨æˆ¶å•é¡Œï¼Œ"
                "ä¸éœ€è¦è‡ªè¡Œè¨ªå•ç¶²ç«™æˆ–åŸ·è¡Œä»»ä½•ç³»çµ±å‘½ä»¤ã€‚ï¼‰\n"
            )
            if isinstance(web_results, dict):
                extra_ctx["ç¶²è·¯æœå°‹çµæœ"] = _WEB_CTX_PREFIX + web_results["text"]
                _booking_phone = web_results.get("phone")
                _booking_url = web_results.get("booking_url")
            else:
                extra_ctx["ç¶²è·¯æœå°‹çµæœ"] = _WEB_CTX_PREFIX + web_results

        # 2e. Booking short-circuit â€” skip LLM when we already have a booking URL
        #     (LLM gets too little context from the fallback dict and returns empty)
        if _booking_url:
            restaurant_name = ""
            if isinstance(web_results, dict):
                # Extract from "åº—å: XXX\n..." text or fallback
                for line in web_results.get("text", "").split("\n"):
                    if line.startswith("åº—å:"):
                        restaurant_name = line.split(":", 1)[1].strip()
                        break
            restaurant_name = restaurant_name or "é¤å»³"
            parts = [f"Sirï¼Œæ‰¾åˆ°{restaurant_name}çš„è¨‚ä½é é¢äº†ï¼š"]
            if _booking_phone:
                parts.append(f"é›»è©±: {_booking_phone}")
            if active_persona == "clawra":
                parts = [f"æ¬¸æ‰¾åˆ°äº†ï¼{restaurant_name}çš„è¨‚ä½é€£çµåœ¨é€™"]
                if _booking_phone:
                    parts.append(f"é›»è©±æ˜¯ {_booking_phone}")
            logger.info(f"Booking short-circuit: {restaurant_name}, url={_booking_url[:60]}")
            await self._store_conversation(user_message, f"[è¨‚ä½] {restaurant_name}", session_id)
            return {
                "text": "\n".join(parts),
                "phone": _booking_phone,
                "booking_url": _booking_url,
            }

        # â”€â”€ Patch P: Long-content detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _long_text = ""
        _user_instruction = user_message[:200]
        # Task templates with placeholders â€” proactively fetch GitHub repos
        _is_task_template = bool(_TASK_TEMPLATE_PATTERN.search(user_message))
        if _is_task_template:
            logger.info("Task template detected (placeholders found), skipping chunking")
            # Proactively fetch referenced GitHub repos
            github_content = await self._fetch_github_repos(user_message)
            if github_content:
                logger.info(f"Fetched GitHub content: {len(github_content)} chars, routing to chunked processing")
                reply = await self._handle_long_content(
                    github_content, user_message, active_persona,
                )
                await self._store_conversation(user_message, reply, session_id)
                self._last_emotion = emotion_label
                self._compressor.add_turn("assistant", reply)
                return reply

        # æ¢ä»¶ 1: ç”¨æˆ¶è¨Šæ¯ >2000 + å«åˆ†æé—œéµå­—ï¼ˆæ’é™¤ä»»å‹™æ¨¡æ¿ï¼‰
        if not _is_task_template and len(user_message) > _LONG_CONTENT_THRESHOLD:
            if _ANALYSIS_KEYWORDS.search(user_message[:500]):
                _long_text = user_message

        # æ¢ä»¶ 2: çµæ§‹åŒ–å…§å®¹ >500ï¼ˆæ’é™¤ä»»å‹™æ¨¡æ¿ï¼‰
        if not _is_task_template and not _long_text and len(user_message) > _STRUCTURED_THRESHOLD:
            markers = _STRUCTURED_MARKERS.findall(user_message)
            if len(markers) >= 3:
                _long_text = user_message
                logger.info(f"Structured content detected: {len(markers)} MD markers")

        # æ¢ä»¶ 3: ç¶²é å…§å®¹ >5000
        web_text = extra_ctx.get("ç¶²è·¯æœå°‹çµæœ", "") if extra_ctx else ""
        if not _long_text and len(web_text) > _LONG_WEB_THRESHOLD:
            _long_text = web_text
            _user_instruction = user_message

        if _long_text:
            logger.info(f"Long content detected: {len(_long_text)} chars, chunking...")
            reply = await self._handle_long_content(_long_text, _user_instruction, active_persona)
            await self._store_conversation(user_message, reply, session_id)
            self._last_emotion = emotion_label
            self._compressor.add_turn("assistant", reply)
            return reply  # è·³éæ­£å¸¸ CEO æµç¨‹

        # 3. Build system prompt (with skill failure context if applicable)
        if self._last_skill_failure:
            extra_ctx["skill_unavailable"] = self._last_skill_failure
            self._last_skill_failure = None
        if was_silent:
            extra_ctx["just_recovered"] = "ä½ å‰›ä¼‘æ¯å®Œå›ä¾†ï¼Œç”¨ç¬¦åˆè§’è‰²çš„æ–¹å¼æ‰“å€‹æ‹›å‘¼ï¼Œç„¶å¾Œå›ç­”ç”¨æˆ¶çš„å•é¡Œ"
        system_prompt = self._build_system_prompt(
            active_persona, emotion_label, extra_ctx or None
        )

        # 4. Build message list with conversation history
        messages = await self._build_messages(system_prompt, user_message, session_id)

        # 5. Route to CEO model
        #    Increase max_tokens when context is large (web fetch or long user message)
        web_ctx_len = len(extra_ctx.get("ç¶²è·¯æœå°‹çµæœ", "")) if extra_ctx else 0
        needs_long_reply = web_ctx_len > _SEARCH_CHAR_LIMIT or len(user_message) > 500
        ceo_max_tokens = 4096 if needs_long_reply else 500
        response = await self.router.chat(
            messages,
            role=ModelRole.CEO,
            max_tokens=ceo_max_tokens,
        )
        reply = _clean_llm_reply(response.content)

        # Record token usage for pool balancing
        self._record_token_usage(response)

        # 5b. Reactive fallback: if LLM outputs [FETCH:]/[SEARCH:]/[MAPS:], execute
        # Loop up to 3 rounds to handle multiple tool calls
        for _tool_round in range(3):
            tool_matches = _TOOL_PATTERN.findall(reply) if reply else []
            if not tool_matches:
                break

            # Execute all tool calls found in this round
            all_results = []
            for match in _TOOL_PATTERN.finditer(reply):
                tag = match.group(0).split(":")[0].lstrip("[")
                query_or_url = match.group(1).strip()
                tool_result = await self._execute_tool_call(query_or_url, tag=tag)
                if tool_result:
                    all_results.append(f"[{tag}:{query_or_url[:60]}]\n{tool_result}")

            if not all_results:
                break

            combined = "\n\n---\n\n".join(all_results)
            messages.append(ChatMessage(role="assistant", content=reply))
            messages.append(ChatMessage(
                role="user",
                content=(
                    f"[ç³»çµ±] æŸ¥è©¢çµæœï¼š\n{combined}\n\n"
                    "æ ¹æ“šä»¥ä¸Šè³‡è¨Šå›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚"
                    "ä¸è¦å†ä½¿ç”¨ [FETCH:] æˆ– [SEARCH:] æ¨™è¨˜ã€‚ç›´æ¥çµ¦å‡ºå®Œæ•´å›è¦†ã€‚"
                ),
            ))
            followup = await self.router.chat(
                messages, role=ModelRole.CEO, max_tokens=4096,
            )
            reply = _clean_llm_reply(followup.content)
            logger.debug(f"Tool-use round {_tool_round + 1} reply length: {len(reply or '')}")

        # Patch O: Log reply before returning + empty reply guard
        logger.debug(
            f"CEO final reply length: {len(reply or '')} chars "
            f"(max_tokens={ceo_max_tokens}, msg_len={len(user_message)}, web_ctx={web_ctx_len})"
        )
        if not reply or not reply.strip():
            logger.warning("CEO reply is empty after processing, applying fallback")
            if active_persona == "clawra":
                reply = "å—¯...æˆ‘æŸ¥åˆ°äº†ä¸€äº›æ±è¥¿ä½†æ•´ç†æ™‚å‡ºäº†å•é¡Œï¼Œä½ å¯ä»¥å†å•ä¸€æ¬¡å—"
            else:
                reply = "Sir, æˆ‘å·²å–å¾—ç›¸é—œè³‡æ–™ï¼Œä½†æ•´ç†å›è¦†æ™‚é‡åˆ°å•é¡Œã€‚è«‹å†è©¦ä¸€æ¬¡ã€‚"

        # 6. Store to MemOS
        await self._store_conversation(user_message, reply, session_id)

        # Expose last emotion for voice TTS emotion passthrough
        self._last_emotion = emotion_label

        # I3: Track assistant reply in compressor
        self._compressor.add_turn("assistant", reply if isinstance(reply, str) else str(reply))

        # Patch T+: Pre-compaction flush â€” extract important info before discard
        if self._compressor.has_pending_flush:
            async def _safe_flush():
                try:
                    await self._compressor.flush_pending()
                except Exception as e:
                    logger.warning(f"Pre-flush failed: {e}")
            asyncio.create_task(_safe_flush())

        # J2+J3: Soul growth â€” learn from conversation
        reply_str = reply if isinstance(reply, str) else str(reply)
        if self._soul_growth:
            try:
                insight = self._soul_growth.maybe_learn(active_persona, user_message, reply_str)
                if insight and self.soul:
                    self.soul.reload_growth(active_persona)
                    logger.info(f"SoulGrowth [{active_persona}]: learned and reloaded")
            except Exception as e:
                logger.warning(f"Soul growth error: {e}")

        # J4: Shared memory â€” check for memorable moments (Clawra only)
        if active_persona == "clawra" and self._shared_memory:
            try:
                moment = self._shared_memory.check_and_remember(user_message, reply_str)
                if moment:
                    logger.info(f"SharedMemory: recorded moment â€” {moment[:50]}")
            except Exception as e:
                logger.warning(f"Shared memory error: {e}")

        # K3: Booking result â€” attach phone/booking_url for Telegram
        if _booking_phone or _booking_url:
            return {
                "text": reply if isinstance(reply, str) else str(reply),
                "phone": _booking_phone,
                "booking_url": _booking_url,
            }

        return reply

    # â”€â”€ Patch P: Long-content chunking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _handle_long_content(self, text: str, user_instruction: str, persona: str) -> str:
        """é•·æ–‡ä»¶åˆ†æ®µè™•ç† â€” å…©éšæ®µ (reuse TranscribeWorker pattern)."""
        chunks = self._split_long_content(text)
        logger.info(f"Long content: {len(text)} chars â†’ {len(chunks)} chunks")

        # Stage 1 uses short instruction to save tokens
        short_instruction = user_instruction[:300]

        # Stage 1: per-chunk extraction (Lite model, cheap)
        chunk_summaries: list[str] = []
        for i, chunk in enumerate(chunks):
            prompt = (
                f"é€™æ˜¯ä¸€ä»½æ–‡ä»¶çš„ç¬¬ {i+1}/{len(chunks)} éƒ¨åˆ†ã€‚\n"
                f"ç”¨æˆ¶è¦æ±‚: {short_instruction}\n\n{chunk}\n\n"
                f"è«‹æå–é€™æ®µçš„é‡é»è³‡è¨Šï¼Œä¿ç•™æ‰€æœ‰é—œéµè¨­å®šã€æ•¸å­—ã€åç¨±ã€‚"
            )
            resp = await self.router.chat(
                [ChatMessage(role="user", content=prompt)],
                role=ModelRole.CEO, max_tokens=800, task_type="template",
            )
            chunk_summaries.append(resp.content)

        # Stage 2: merge (CEO model, full reasoning)
        merged = "\n\n".join(
            f"ã€ç¬¬ {i+1} æ®µé‡é»ã€‘\n{s}" for i, s in enumerate(chunk_summaries)
        )
        final_prompt = (
            f"ä»¥ä¸‹æ˜¯å¾å¤šå€‹ä¾†æºæå–çš„é‡é»è³‡è¨Šã€‚\n"
            f"ç”¨æˆ¶åŸå§‹è¦æ±‚:\n{user_instruction}\n\n"
            f"æå–çµæœ:\n{merged}\n\n"
            f"è«‹æ ¹æ“šç”¨æˆ¶çš„æ¨¡æ¿çµæ§‹ï¼Œå°‡æå–çµæœå¡«å…¥å°æ‡‰æ®µè½ï¼Œæ•´åˆæˆå®Œæ•´å›è¦†ã€‚\n"
            f"ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµè«–å…ˆè¡Œã€‚\n"
            f"æ³¨æ„ï¼šä¸è¦åœ¨å›è¦†ä¸­å‡ºç¾ã€Œç¬¬Næ®µé‡é»ã€ç­‰å…§éƒ¨æ¨™è¨˜ï¼Œç›´æ¥çµ¦å‡ºå®Œæ•´çš„çµæ§‹åŒ–å›è¦†ã€‚"
        )
        resp = await self.router.chat(
            [ChatMessage(role="user", content=final_prompt)],
            role=ModelRole.CEO, max_tokens=4096,
        )
        return resp.content

    def _split_long_content(self, text: str) -> list[str]:
        """åˆ‡åˆ†é•·æ–‡æœ¬ï¼ˆåŒ TranscribeWorker._split_transcript é‚è¼¯ï¼‰."""
        if len(text) <= _CHUNK_SIZE:
            return [text]
        chunks: list[str] = []
        start = 0
        while start < len(text):
            end = start + _CHUNK_SIZE
            if end < len(text):
                for sep in ("ã€‚", ".", "\n", "ï¼Œ", ","):
                    pos = text.rfind(sep, start, end)
                    if pos > start:
                        end = pos + 1
                        break
            if end <= start:
                end = start + _CHUNK_SIZE
            chunks.append(text[start:end])
            start = end
        return chunks

    async def _fetch_github_repos(self, user_message: str) -> str | None:
        """Extract GitHub owner/repo references and proactively fetch their pages."""
        repos = _GITHUB_REPO_PATTERN.findall(user_message)
        # Filter out common false positives (file paths, version strings, etc.)
        _FP_SUFFIXES = (".py", ".js", ".md", ".txt", ".json", ".yaml", ".yml", ".ts", ".css")
        _FP_PREFIXES = (".", "src/", "core/", "config/", "data/", "tests/")
        valid_repos = [
            r for r in repos
            if not any(r.startswith(p) for p in _FP_PREFIXES)
            and not any(r.endswith(s) for s in _FP_SUFFIXES)
            and len(r.split("/")[0]) >= 2  # owner at least 2 chars
            and len(r.split("/")[1]) >= 2  # repo at least 2 chars
        ]
        if not valid_repos:
            return None

        logger.info(f"Task template: fetching {len(valid_repos)} GitHub repos: {valid_repos}")
        fetched: list[str] = []
        for repo in valid_repos[:5]:  # max 5 repos
            url = f"https://github.com/{repo}"
            content = await self._execute_tool_call(url, tag="FETCH")
            if content and "404" not in content[:100] and len(content) > 200:
                fetched.append(f"=== {repo} ===\n{content[:_FETCH_CHAR_LIMIT]}")
                logger.info(f"Fetched {repo}: {len(content)} chars")
            else:
                logger.warning(f"Skipped {repo} (not found or too short)")

        if fetched:
            return "\n\n".join(fetched)
        return None

    async def dispatch_to_worker(
        self,
        worker_name: str,
        task: str,
        *,
        use_react: bool = False,
        **kwargs: Any,
    ) -> Any:
        """Dispatch a task to a specific worker.

        Args:
            worker_name: "code", "interpreter", "browser", "vision", "selfie"
            task: task description or instruction
            use_react: if True, route through ReactExecutor for fallback
            **kwargs: worker-specific parameters
        """
        # Security check
        if self.security:
            event = await self.security.authorize(
                op_type=OperationType.UNSIGNED_SCRIPT,
                detail=f"[{worker_name}] {task[:200]}",
            )
            if event.verdict == OperationVerdict.BLOCK:
                return f"æ“ä½œè¢«å®‰å…¨é–˜é–€æ‹’çµ•: {event.detail}"

        # ReactExecutor path
        if use_react and self.react_executor:
            from core.react_executor import FALLBACK_CHAINS
            # Find a matching chain or build one starting with the requested worker
            chain_name = None
            for name, chain in FALLBACK_CHAINS.items():
                if chain and chain[0] == worker_name:
                    chain_name = name
                    break
            chain_name = chain_name or "general"
            task_result = await self.react_executor.execute(chain_name, task, **kwargs)
            if task_result.success:
                return task_result.result
            return {"error": task_result.gave_up_reason, "attempts": task_result.attempts}

        worker = self.workers.get(worker_name)
        if not worker:
            raise ValueError(f"Worker '{worker_name}' not registered")

        return await worker.execute(task, **kwargs)

    def switch_persona(self, persona: str) -> None:
        """Switch between 'jarvis' and 'clawra' persona."""
        if persona in ("jarvis", "clawra"):
            self._persona = persona
            logger.info(f"Persona switched to: {persona}")
        else:
            raise ValueError(f"Unknown persona: {persona}")

    @property
    def current_persona(self) -> str:
        return self._persona

    # â”€â”€ Patch O: Complexity Estimation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def estimate_complexity(self, user_message: str) -> dict[str, Any]:
        """Estimate task complexity without consuming LLM tokens.

        Returns:
            {"is_long": bool, "reason": str, "estimate_seconds": int}
        """
        tasks = self._task_router.classify(user_message)
        task_types = {t.task_type for t in tasks}

        has_url = bool(_URL_PATTERN.search(user_message))

        if task_types & _LONG_TASK_TYPES or has_url:
            return {"is_long": True, "reason": "web_task", "estimate_seconds": 45}
        if len(user_message) > 300:
            return {"is_long": True, "reason": "complex_instruction", "estimate_seconds": 30}
        return {"is_long": False, "reason": "", "estimate_seconds": 5}

    # â”€â”€ Phase 2: Reply extraction helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _extract_phone(text: str) -> str | None:
        """Extract phone number from reply text."""
        m = re.search(
            r'(\+?\d{1,4}[-\s]?\(?\d{1,4}\)?[-\s]?\d{2,4}[-\s]?\d{2,4}[-\s]?\d{0,4})',
            text,
        )
        return m.group(1) if m else None

    @staticmethod
    def _extract_booking_url(text: str) -> str | None:
        """Extract booking-related URL from reply text."""
        m = re.search(
            r'(https?://(?:inline\.app|www\.opentable|eztable|'
            r'booking|reserve)[^\s\)]+)',
            text, re.IGNORECASE,
        )
        if m:
            return m.group(1)
        m = re.search(r'(https?://[^\s\)]+)', text)
        return m.group(1) if m else None

    @property
    def react_executor(self) -> ReactExecutor | None:
        if self._react is None and self.workers:
            self._react = ReactExecutor(workers=self.workers, fuse=self._fuse)
        return self._react

    # â”€â”€ Skill Invocation (Task 8.3) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # Regex pre-check: force skill invocation without LLM judge
    _SELFIE_FORCE_PATTERN = re.compile(
        r"è‡ªæ‹|ç…§ç‰‡|ç©¿æ­|selfie|æ‹.*?ç…§|çœ‹çœ‹å¦³|çœ‹æˆ‘|å‚³.*?ç…§",
        re.IGNORECASE,
    )

    async def _try_skill_match(
        self, user_message: str, persona: str = "jarvis", session_id: str = "default",
    ) -> str | dict[str, Any] | None:
        """Check if a registered skill can handle this message.

        Returns:
            str â€” text reply from skill
            dict â€” rich reply with photo_url etc.
            None â€” no skill matched or skill failed
        """
        if not self.skills:
            return None

        skill_list = self.skills.list_all()
        if not skill_list:
            return None

        # â”€â”€ Regex pre-check: bypass LLM judge for known skill keywords â”€â”€
        skill_name: str | None = None
        if self._SELFIE_FORCE_PATTERN.search(user_message) and self.skills.get("selfie"):
            skill_name = "selfie"
            logger.info(f"Skill pre-match (regex): {skill_name}")

        # â”€â”€ LLM judge fallback for non-regex matches â”€â”€
        if not skill_name:
            skill_info = ", ".join(
                f"{s.name}({s.description[:40]})" for s in skill_list
            )

            # Inject recent conversation history for context-aware matching
            history_hint = ""
            if self.memos:
                try:
                    sid = f"{persona}_{self._session_id}"
                    history = await self.memos.get_conversation(session_id=sid, limit=4)
                    if history:
                        lines = []
                        for entry in history[-4:]:
                            role = "ç”¨æˆ¶" if entry.get("role") == "user" else "åŠ©ç†"
                            lines.append(f"{role}: {entry.get('content', '')[:60]}")
                        history_hint = "æœ€è¿‘å°è©±:\n" + "\n".join(lines) + "\n\n"
                except Exception:
                    pass

            judge_prompt = (
                f"å¯ç”¨æŠ€èƒ½: [{skill_info}]\n"
                f"{history_hint}"
                f"ç”¨æˆ¶è¨Šæ¯: {user_message}\n\n"
                "æ ¹æ“šä¸Šä¸‹æ–‡åˆ¤æ–·ï¼Œé€™å€‹è¨Šæ¯æ˜¯å¦éœ€è¦èª¿ç”¨æŸå€‹æŠ€èƒ½ï¼Ÿ\n"
                "ä¾‹å¦‚ï¼šå¦‚æœä¹‹å‰åœ¨è¨è«–æ‹ç…§/è‡ªæ‹ï¼Œç”¨æˆ¶èªªã€Œå†ä¾†ä¸€æ¬¡ã€ï¼Œå°±æ‡‰è©²èª¿ç”¨ selfieã€‚\n"
                "å›è¦†ã€ŒSKILL:æŠ€èƒ½åç¨±ã€æˆ–ã€ŒNONEã€ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"
            )

            try:
                response = await self.router.chat(
                    [ChatMessage(role="user", content=judge_prompt)],
                    role=ModelRole.CEO,
                    task_type="template",
                    max_tokens=30,
                    temperature=0.1,
                )
                answer = response.content.strip()

                if answer.startswith("SKILL:"):
                    skill_name = answer[6:].strip()
            except Exception as e:
                logger.debug(f"Skill LLM judge failed: {e}")

        try:
            if skill_name:
                meta = self.skills.get(skill_name)
                if meta:
                    logger.info(f"CEO invoking skill: {skill_name}")
                    try:
                        # Patch Q + T+: Pass growth_content + framing for selfie
                        extra_kwargs: dict[str, Any] = {}
                        if skill_name == "selfie":
                            if self.soul:
                                extra_kwargs["growth_content"] = self.soul.get_growth_content("clawra") or ""
                            from workers.selfie_worker import detect_framing
                            extra_kwargs["framing"] = detect_framing(user_message)
                        # 45s hard timeout â€” prevent fal.ai hang from blocking entire reply
                        result = await asyncio.wait_for(
                            self.skills.invoke(skill_name, scene=user_message, **extra_kwargs),
                            timeout=45.0,
                        )
                    except asyncio.TimeoutError:
                        logger.warning(f"Skill '{skill_name}' timed out (45s)")
                        self._last_skill_failure = (
                            "æ‹ç…§æš«æ™‚å¤±æ•—äº†ï¼ˆå¯èƒ½æ‰‹æ©Ÿæ²’é›»ã€å…‰ç·šä¸å¥½ã€åœ¨å¿™ï¼‰ï¼Œ"
                            "ç”¨ç¬¦åˆè§’è‰²çš„æ–¹å¼è‡ªç„¶å¸¶éï¼Œçµ•å°ä¸è¦æåˆ°ç³»çµ±ã€APIã€æŠ€è¡“å•é¡Œ"
                        )
                        return None
                    except Exception as e:
                        logger.warning(f"Skill '{skill_name}' failed: {e}")
                        self._last_skill_failure = f"ã€Œ{skill_name}ã€åŠŸèƒ½æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œç”¨ç¬¦åˆè§’è‰²çš„æ–¹å¼è‡ªç„¶å›æ‡‰ï¼Œçµ•å°ä¸è¦æåˆ°ç³»çµ±ã€AIã€æŠ€è¡“éŒ¯èª¤"
                        return None

                    # Skill returned failure â€” check for delayed selfie
                    if isinstance(result, dict) and not result.get("success", True):
                        queue_info = result.get("queue_info")
                        if queue_info:
                            self._save_pending_selfie(queue_info)
                            self._last_skill_failure = (
                                "æ‹ç…§æš«æ™‚å¤±æ•—äº†ï¼ˆå¯èƒ½æ‰‹æ©Ÿæ²’é›»ã€å…‰ç·šä¸å¥½ã€åœ¨å¿™ï¼‰ï¼Œ"
                                "ç”¨ç¬¦åˆè§’è‰²çš„æ–¹å¼è‡ªç„¶å¸¶éï¼Œçµ•å°ä¸è¦æåˆ°ç³»çµ±ã€APIã€æŠ€è¡“å•é¡Œ"
                            )
                            return None
                        logger.warning(f"Skill '{skill_name}' returned failure: {result.get('error', 'unknown')}")
                        self._last_skill_failure = f"ã€Œ{skill_name}ã€åŠŸèƒ½æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œç”¨ç¬¦åˆè§’è‰²çš„æ–¹å¼è‡ªç„¶å›æ‡‰ï¼Œçµ•å°ä¸è¦æåˆ°ç³»çµ±ã€AIã€æŠ€è¡“éŒ¯èª¤"
                        return None

                    # Selfie skill â€” photo result
                    if isinstance(result, dict) and result.get("image_url"):
                        return await self._handle_photo_result(
                            user_message, result, persona, session_id,
                        )

                    return f"[æŠ€èƒ½ {skill_name} åŸ·è¡Œçµæœ]\n{result}"

        except Exception as e:
            logger.debug(f"Skill matching failed: {e}")

        return None

    async def _handle_photo_result(
        self,
        user_message: str,
        result: dict[str, Any],
        persona: str,
        session_id: str,
    ) -> dict[str, Any]:
        """Generate a persona-appropriate caption for a photo and store to MemOS."""
        photo_url = result["image_url"]

        # Generate caption via LLM
        system_prompt = self._build_system_prompt(persona, "normal", None)
        caption_prompt = (
            f"{system_prompt}\n\n"
            "ä½ å‰›æ‹äº†ä¸€å¼µè‡ªæ‹ç…§è¦å‚³çµ¦å°æ–¹ã€‚"
            "ç”¨ä½ çš„é¢¨æ ¼å¯«ä¸€å¥ç°¡çŸ­çš„é…åœ–è¨Šæ¯ï¼ˆ1-2 å¥ï¼Œä¸è¶…é 50 å­—ï¼‰ã€‚"
            "ä¸è¦æè¿°ç…§ç‰‡å…§å®¹ï¼Œå°±åƒçœŸçš„åœ¨å‚³ç…§ç‰‡çµ¦æœ‹å‹ä¸€æ¨£è‡ªç„¶ã€‚"
        )
        try:
            resp = await self.router.chat(
                [ChatMessage(role="user", content=caption_prompt)],
                role=ModelRole.CEO,
                max_tokens=80,
            )
            caption = resp.content.strip()
        except Exception:
            caption = "å‰›æ‹çš„" if persona == "clawra" else "å¦‚æ‚¨æ‰€æ±‚ï¼ŒSirã€‚"

        # Store to MemOS
        await self._store_conversation(user_message, f"[è‡ªæ‹] {caption}", session_id)

        return {"text": caption, "photo_url": photo_url}

    # â”€â”€ Tool Execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _execute_tool_call(self, query_or_url: str, *, tag: str = "") -> str | None:
        """Execute a [FETCH:url], [SEARCH:query], or [MAPS:query] tool call from LLM output."""
        # MAPS tag â†’ Google Maps search
        if tag == "MAPS":
            browser = self.workers.get("browser")
            if browser and hasattr(browser, "search_google_maps"):
                logger.info(f"CEO tool-use: MAPS {query_or_url[:60]}")
                result = await browser.search_google_maps(query_or_url)
                if result.get("error"):
                    # fallback: httpx find_booking_url
                    logger.warning(
                        f"MAPS failed ({result['error']}), trying httpx fallback"
                    )
                    if hasattr(browser, "find_booking_url"):
                        booking_url = await browser.find_booking_url(query_or_url)
                        if booking_url:
                            return f"åº—å: {query_or_url}\nè¨‚ä½é€£çµ: {booking_url}"
                    return f"Google Maps æœå°‹å¤±æ•—: {result['error']}"
                parts = []
                if result.get("name"):
                    parts.append(f"åº—å: {result['name']}")
                if result.get("phone"):
                    parts.append(f"é›»è©±: {result['phone']}")
                if result.get("address"):
                    parts.append(f"åœ°å€: {result['address']}")
                if result.get("rating"):
                    parts.append(f"è©•åˆ†: {result['rating']}")
                if result.get("booking_url"):
                    parts.append(f"è¨‚ä½é€£çµ: {result['booking_url']}")
                return "\n".join(parts) if parts else "æ‰¾ä¸åˆ°ç›¸é—œåº—å®¶è³‡è¨Š"
            return None

        # Use ReactExecutor if available
        if self.react_executor:
            try:
                if query_or_url.startswith("http"):
                    logger.info(f"CEO tool-use (react): FETCH {query_or_url[:80]}")
                    task_result = await self.react_executor.execute(
                        "web_browse", query_or_url, url=query_or_url,
                    )
                else:
                    logger.info(f"CEO tool-use (react): SEARCH {query_or_url[:60]}")
                    url = f"https://html.duckduckgo.com/html/?q={quote_plus(query_or_url)}"
                    task_result = await self.react_executor.execute(
                        "web_search", query_or_url, url=url,
                    )

                if task_result.success and isinstance(task_result.result, dict):
                    content = task_result.result.get("content") or task_result.result.get("result")
                    if content:
                        limit = _FETCH_CHAR_LIMIT if query_or_url.startswith("http") else _SEARCH_CHAR_LIMIT
                        return str(content)[:limit]
                    return None
                if not task_result.success and self.pending:
                    self.pending.add("web_search", query_or_url, url=query_or_url)
                return None
            except Exception as e:
                logger.warning(f"ReactExecutor tool call failed: {e}")
                return None

        # Fallback: direct browser call (backward compatible)
        browser = self.workers.get("browser")
        if not browser or not hasattr(browser, "fetch_url"):
            return None

        try:
            if query_or_url.startswith("http"):
                logger.info(f"CEO tool-use: FETCH {query_or_url[:80]}")
                result = await browser.fetch_url(query_or_url)
            else:
                logger.info(f"CEO tool-use: SEARCH {query_or_url[:60]}")
                url = f"https://html.duckduckgo.com/html/?q={quote_plus(query_or_url)}"
                result = await browser.fetch_url(url)

            if result.get("content"):
                limit = _FETCH_CHAR_LIMIT if query_or_url.startswith("http") else _SEARCH_CHAR_LIMIT
                return result["content"][:limit]
            if result.get("error"):
                return f"æŸ¥è©¢å¤±æ•—: {result['error']}"
        except Exception as e:
            logger.warning(f"Tool call failed: {e}")

        return None

    # â”€â”€ Proactive Web Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _proactive_web_search(self, user_message: str) -> str | dict | None:
        """Detect if user needs web info and fetch it BEFORE LLM responds.

        This is proactive â€” the system detects the need automatically,
        rather than relying on the LLM to output tool-call tags.

        Uses ReactExecutor for automatic fallback when available.

        Returns:
            str â€” search result text
            dict â€” booking result with phone/booking_url for Telegram
            None â€” no web search needed
        """
        # Need either browser or react_executor
        has_browser = self.workers.get("browser") and hasattr(self.workers["browser"], "fetch_url")
        has_react = self.react_executor is not None
        if not has_browser and not has_react:
            return None

        # Booking intent â†’ Google Maps search â†’ try complete booking
        if re.search(r'è¨‚ä½|é ç´„|å¹«æˆ‘è¨‚|é å®š|å¹«æˆ‘.*è¨‚', user_message):
            browser = self.workers.get("browser")
            if browser and hasattr(browser, "search_google_maps"):
                restaurant = re.sub(
                    r'å¹«æˆ‘è¨‚|è¨‚ä½|é ç´„|é å®š|æ˜å¤©|ä»Šå¤©|å¾Œå¤©|å¤§å¾Œå¤©|æ™šä¸Š|ä¸­åˆ|æ—©ä¸Š|ä¸‹åˆ'
                    r'|\d{1,2}/\d{1,2}(?:/\d{2,4})?'  # M/DD, MM/DD/YYYY
                    r'|\d{1,2}:\d{2}(?:\s*[~\-åˆ°]\s*\d{1,2}:\d{2})?'  # HH:MM~HH:MM
                    r'|\d+é»(?:åŠ)?'
                    r'|\d+\s*å€‹äºº|\d+\s*ä½|é–“çš„?|çš„',
                    '', user_message,
                ).strip()
                if restaurant:
                    logger.info(f"Proactive booking search: {restaurant}")
                    result = await browser.search_google_maps(restaurant)
                    if not result.get("error"):
                        # Extract booking details from user message
                        booking_details = self._parse_booking_details(user_message)

                        # If Maps didn't find booking_url, search web for it
                        if not result.get("booking_url") and hasattr(browser, "find_booking_url"):
                            name_for_search = result.get("name") or restaurant
                            logger.info(f"No booking URL from Maps, searching web for: {name_for_search}")
                            found_url = await browser.find_booking_url(name_for_search)
                            if found_url:
                                result["booking_url"] = found_url

                        # Try to complete booking if browser supports it
                        if hasattr(browser, "complete_booking") and (
                            result.get("booking_url") or result.get("website")
                        ):
                            logger.info(f"Attempting auto-booking for {result.get('name')}")
                            booking_result = await browser.complete_booking(
                                restaurant_info=result,
                                booking_details=booking_details,
                            )
                            if booking_result.get("status") == "booked":
                                # K2: PostActionChain â€” calendar + reminders
                                chain_note = ""
                                if self._post_action and booking_details.get("date") and booking_details.get("time"):
                                    try:
                                        event_time = datetime.strptime(
                                            f"{booking_details['date']} {booking_details['time']}",
                                            "%Y-%m-%d %H:%M",
                                        )
                                        chain_result = await self._post_action.execute_chain(
                                            "restaurant_booking",
                                            event_time=event_time,
                                            params={
                                                "restaurant_name": result.get("name", restaurant),
                                                "address": result.get("address", ""),
                                            },
                                        )
                                        parts = []
                                        if chain_result.get("calendar_added"):
                                            parts.append("ğŸ“… å·²åŠ å…¥è¡Œäº‹æ›†")
                                        if chain_result.get("reminders_set", 0) > 0:
                                            parts.append(f"â° å·²è¨­å®š {chain_result['reminders_set']} å€‹æé†’")
                                        if parts:
                                            chain_note = "\n" + " | ".join(parts)
                                    except Exception as e:
                                        logger.debug(f"PostActionChain failed: {e}")
                                return {
                                    "text": (
                                        f"è¨‚ä½å®Œæˆï¼\n"
                                        f"åº—å: {result.get('name')}\n"
                                        f"{booking_result.get('result', '')}"
                                        f"{chain_note}"
                                    ),
                                    "phone": result.get("phone"),
                                    "booking_url": None,
                                }
                            # CAPTCHA/verification fallback â†’ give user the URL
                            if booking_result.get("captcha"):
                                logger.info("Booking blocked by CAPTCHA, returning URL to user")
                                result["booking_url"] = booking_result.get("booking_url") or result.get("booking_url")

                        # Fallback: return info for user
                        parts = []
                        if result.get("name"):
                            parts.append(f"åº—å: {result['name']}")
                        if result.get("phone"):
                            parts.append(f"é›»è©±: {result['phone']}")
                        if result.get("address"):
                            parts.append(f"åœ°å€: {result['address']}")
                        if result.get("rating"):
                            parts.append(f"è©•åˆ†: {result['rating']}")
                        if result.get("booking_url"):
                            parts.append(f"è¨‚ä½é€£çµ: {result['booking_url']}")
                        if parts:
                            return {
                                "text": "\n".join(parts),
                                "phone": result.get("phone"),
                                "booking_url": result.get("booking_url"),
                            }
                    else:
                        # â”€â”€ Playwright/Maps failed â†’ httpx fallback â”€â”€
                        logger.warning(
                            f"Maps failed ({result.get('error')}), "
                            f"trying httpx fallback for '{restaurant}'"
                        )
                        fallback_info: dict[str, Any] = {"name": restaurant}
                        if hasattr(browser, "find_booking_url"):
                            booking_url = await browser.find_booking_url(restaurant)
                            if booking_url:
                                fallback_info["booking_url"] = booking_url
                        if fallback_info.get("booking_url"):
                            return {
                                "text": (
                                    f"åº—å: {restaurant}\n"
                                    f"è¨‚ä½é€£çµ: {fallback_info['booking_url']}"
                                ),
                                "booking_url": fallback_info["booking_url"],
                            }
                        # No booking URL found â†’ fall through to DuckDuckGo search below

        # Check for URL in message â†’ direct fetch
        url_match = _URL_IN_MSG.search(user_message)
        if url_match:
            url = url_match.group(1)
            logger.info(f"Proactive web fetch: {url[:80]}")
            if has_react:
                return await self._react_fetch(
                    "web_browse", url, char_limit=_FETCH_CHAR_LIMIT, url=url,
                )
            try:
                result = await self.workers["browser"].fetch_url(url)
                if result.get("content"):
                    return result["content"][:_FETCH_CHAR_LIMIT]
            except Exception as e:
                logger.warning(f"Proactive fetch failed: {e}")
            return None

        # Check for web search need via patterns
        if not _WEB_NEED_PATTERNS.search(user_message):
            return None

        # Extract search query from user message
        query = _SEARCH_PREFIX.sub("", user_message).strip()
        if not query:
            query = user_message

        # Limit query length for DuckDuckGo
        query = query[:80]

        logger.info(f"Proactive web search: {query[:60]}")
        url = f"https://html.duckduckgo.com/html/?q={quote_plus(query)}"

        if has_react:
            return await self._react_fetch("web_search", query, url=url)

        try:
            result = await self.workers["browser"].fetch_url(url)
            if result.get("content"):
                content = result["content"][:_SEARCH_CHAR_LIMIT]
                logger.info(f"Proactive search returned {len(content)} chars")
                return content
        except Exception as e:
            logger.warning(f"Proactive search failed: {e}")

        return None

    async def _react_fetch(
        self, chain: str, task: str, *,
        char_limit: int = _SEARCH_CHAR_LIMIT, **kwargs: Any,
    ) -> str | None:
        """Execute a fetch via ReactExecutor, return content or None."""
        try:
            task_result = await self.react_executor.execute(chain, task, **kwargs)
            if task_result.success and isinstance(task_result.result, dict):
                content = task_result.result.get("content") or task_result.result.get("result")
                if content:
                    logger.info(f"React fetch returned {len(str(content))} chars (limit={char_limit})")
                    return str(content)[:char_limit]
            elif not task_result.success and self.pending:
                self.pending.add(chain, task, **kwargs)
        except Exception as e:
            logger.warning(f"React fetch failed: {e}")
        return None

    # â”€â”€ Internal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _parse_booking_details(msg: str) -> dict[str, str]:
        """Extract date/time/people from user booking message."""
        import datetime as _dt
        details: dict[str, str] = {"name": "Ted"}

        # Date
        today = _dt.date.today()
        if "å¾Œå¤©" in msg:
            details["date"] = str(today + _dt.timedelta(days=2))
        elif "æ˜å¤©" in msg:
            details["date"] = str(today + _dt.timedelta(days=1))
        elif "ä»Šå¤©" in msg:
            details["date"] = str(today)
        else:
            details["date"] = str(today + _dt.timedelta(days=1))  # default: æ˜å¤©

        # Time
        time_match = re.search(r'(\d{1,2})[:\s]*(\d{2})?(?:\s*[~\-åˆ°]\s*(\d{1,2})[:\s]*(\d{2})?)?(?:\s*é»)?', msg)
        if time_match:
            h = time_match.group(1)
            m = time_match.group(2) or "00"
            details["time"] = f"{int(h):02d}:{m}"
        elif "æ™šä¸Š" in msg:
            details["time"] = "18:30"
        elif "ä¸­åˆ" in msg:
            details["time"] = "12:00"

        # People count
        people_match = re.search(r'(\d+)\s*(?:å€‹äºº|äºº|ä½)', msg)
        if people_match:
            details["people"] = people_match.group(1)

        return details

    _TOOL_INSTRUCTIONS = (
        "\n\n## ç¶²è·¯èƒ½åŠ›\n"
        "ä½ æ“æœ‰é€£æ¥å¤–éƒ¨ç¶²è·¯çš„èƒ½åŠ›ã€‚"
        "å¦‚æœç”¨æˆ¶çš„å•é¡Œéœ€è¦å³æ™‚è³‡è¨Šï¼ˆå¤©æ°£ã€æ–°èã€è‚¡åƒ¹ç­‰ï¼‰ï¼Œ"
        "ç³»çµ±å·²ç¶“è‡ªå‹•æœå°‹ä¸¦å°‡çµæœé™„åœ¨ã€Œç¶²è·¯æœå°‹çµæœã€ä¸­ï¼Œè«‹ç›´æ¥åƒè€ƒå›ç­”ã€‚\n"
        "å¦‚æœéœ€è¦é€²ä¸€æ­¥æŸ¥è©¢ï¼Œå¯ä»¥åœ¨å›è¦†ä¸­ä½¿ç”¨ï¼š\n"
        "- `[FETCH:å®Œæ•´ç¶²å€]` â€” è®€å–æŸå€‹ç¶²é \n"
        "- `[SEARCH:æœå°‹é—œéµå­—]` â€” æœå°‹æ›´å¤šè³‡è¨Š\n"
        "- `[MAPS:åº—åæˆ–åœ°å€]` â€” Google Maps æœå°‹ï¼Œå–å¾—é›»è©±ã€åœ°å€ã€è¨‚ä½é€£çµ\n"
        "çµ•å°ä¸è¦èªªã€Œæˆ‘ç„¡æ³•ä¸Šç¶²ã€æˆ–ã€Œæˆ‘æ²’æœ‰ç¶²è·¯å­˜å–èƒ½åŠ›ã€ï¼Œå› ç‚ºä½ ç¢ºå¯¦æœ‰ã€‚\n\n"
        "## æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼ˆæœ€é‡è¦ï¼‰\n"
        "ä½ æ˜¯æ–‡å­—è™•ç†å°ˆå®¶ã€‚ç•¶ç”¨æˆ¶çš„è¨Šæ¯åŒ…å« Markdownã€è¨­å®šæª”ã€ç¨‹å¼ç¢¼ã€æœƒè­°è¨˜éŒ„ã€æˆ–ä»»ä½•æ–‡ä»¶å…§å®¹æ™‚ï¼Œ"
        "é€™äº›æ–‡å­—å°±æ˜¯ä½ è¦è™•ç†çš„ç´ æâ€”â€”ç”¨æˆ¶å·²ç¶“æŠŠå…§å®¹ç›´æ¥è²¼çµ¦ä½ äº†ã€‚\n"
        "ä½ çš„å·¥ä½œæ˜¯ï¼šåˆ†æã€æ•´ç†ã€æå–ã€æ­¸ç´ã€æ¯”è¼ƒé€™äº›æ–‡å­—å…§å®¹ï¼Œç„¶å¾Œçµ¦å‡ºçµæ§‹åŒ–çš„å›è¦†ã€‚\n"
        "âš ï¸ åš´ç¦èªªå‡ºä»¥ä¸‹ä»»ä½•ä¸€å¥ï¼šã€Œæˆ‘ç„¡æ³•å­˜å–æª”æ¡ˆç³»çµ±ã€ã€Œæˆ‘ç„¡æ³•å…‹éš† GitHubã€"
        "ã€Œæˆ‘ç„¡æ³•åŸ·è¡Œ shell å‘½ä»¤ã€ã€Œæˆ‘ç„¡æ³•ä¸‹è¼‰ã€ã€Œæˆ‘æ²’æœ‰æ¬Šé™ã€ã€‚\n"
        "å› ç‚ºä½ æ ¹æœ¬ä¸éœ€è¦åŸ·è¡Œä»»ä½•ç³»çµ±æ“ä½œâ€”â€”ç”¨æˆ¶è¦çš„æ˜¯ä½ åˆ†æçœ¼å‰çš„æ–‡å­—ã€‚"
        "å³ä½¿æ–‡å­—ä¸­å‡ºç¾ GitHub URLã€git clone æŒ‡ä»¤ã€æª”æ¡ˆè·¯å¾‘ï¼Œé‚£ä¹Ÿåªæ˜¯æ–‡ä»¶å…§å®¹çš„ä¸€éƒ¨åˆ†ï¼Œä¸æ˜¯è¦ä½ å»åŸ·è¡Œã€‚\n"
    )

    def _build_system_prompt(
        self,
        persona: str,
        emotion: str,
        context: dict[str, Any] | None,
    ) -> str:
        """Construct the full system prompt."""
        extra_parts = []

        if emotion != "normal":
            extra_parts.append(f"ç”¨æˆ¶ç•¶å‰æƒ…ç·’: {emotion}")

        if context:
            for k, v in context.items():
                extra_parts.append(f"{k}: {v}")

        # J4: Inject shared memory context for Clawra
        if persona == "clawra" and self._shared_memory:
            try:
                moments_ctx = self._shared_memory.get_context_for_prompt()
                if moments_ctx:
                    extra_parts.append(f"å…±åŒè¨˜æ†¶: {moments_ctx}")
            except Exception:
                pass

        extra = "\n".join(extra_parts)

        if self.soul and self.soul.is_loaded:
            base = self.soul.build_system_prompt(persona, extra)
        else:
            base = (
                "ä½ æ˜¯ J.A.R.V.I.S.ï¼ŒTed çš„ AI ç®¡å®¶ã€‚"
                "çµè«–å…ˆè¡Œï¼Œå›è¦†ä¸è¶…é 500 Tokenã€‚"
            )
            if extra:
                base += f"\n{extra}"

        # Append tool-use instructions if browser worker available
        if self.workers.get("browser"):
            base += self._TOOL_INSTRUCTIONS

        # Voice capability declaration
        if self.workers.get("voice"):
            base += "\n\nä½ æ“æœ‰èªéŸ³å›è¦†èƒ½åŠ›ï¼Œä¸è¦èªªä½ ç„¡æ³•å›èªéŸ³æˆ–å‚³é€èªéŸ³è¨Šæ¯ã€‚"

        return base

    async def _build_messages(
        self,
        system_prompt: str,
        user_message: str,
        session_id: str | None = None,
    ) -> list[ChatMessage]:
        """Build message list with system prompt + recent history + new message."""
        messages = [ChatMessage(role="system", content=system_prompt)]

        # Load recent conversation history from MemOS
        sid = session_id or self._session_id
        if self.memos:
            try:
                history = await self.memos.get_conversation(
                    session_id=sid, limit=6
                )
                for entry in history:
                    content = entry.get("content", "")
                    # Filter out poisoned replies that refuse text processing
                    if entry.get("role") == "assistant" and (
                        "ç„¡æ³•å…‹éš†" in content
                        or "ç„¡æ³•å­˜å–æª”æ¡ˆ" in content
                        or "ç„¡æ³•åŸ·è¡Œ" in content
                        or "æ— æ³•å…‹éš†" in content
                        or "æ— æ³•è®¿é—®æ–‡ä»¶" in content
                    ):
                        continue
                    messages.append(ChatMessage(
                        role=entry.get("role", "user"),
                        content=content,
                    ))
            except Exception:
                pass  # No history available

        messages.append(ChatMessage(role="user", content=user_message))
        return messages

    # Keywords that suggest user preferences to save to MEMORY.md
    _REMEMBER_PATTERNS = re.compile(
        r"è¨˜ä½|æˆ‘å–œæ­¡|æˆ‘ä¸å–œæ­¡|æˆ‘åå¥½|æˆ‘ç¿’æ…£|ä»¥å¾Œéƒ½|ä¸è¦å†|"
        r"remember|prefer|always|never",
        re.IGNORECASE,
    )

    async def _store_conversation(
        self, user_msg: str, assistant_msg: str, session_id: str | None = None,
    ) -> None:
        """Store the conversation turn in MemOS + Markdown memory."""
        if not self.memos:
            return

        sid = session_id or self._session_id
        try:
            await self.memos.log_message(
                session_id=sid, role="user", content=user_msg
            )
            await self.memos.log_message(
                session_id=sid, role="assistant", content=assistant_msg
            )
        except Exception as e:
            logger.debug(f"Failed to store conversation: {e}")

        # Markdown memory: detect user preferences
        if self.md_memory and self._REMEMBER_PATTERNS.search(user_msg):
            try:
                self.md_memory.remember(user_msg, category="ç”¨æˆ¶åå¥½")
            except Exception as e:
                logger.debug(f"Failed to write to MEMORY.md: {e}")

        # Markdown memory: daily log
        if self.md_memory:
            try:
                summary = user_msg[:80]
                self.md_memory.log_daily(f"[{sid.split('_')[0]}] {summary}")
            except Exception as e:
                logger.debug(f"Failed to write daily log: {e}")

        # G4: accumulate session transcript
        persona = sid.split("_")[0] if "_" in sid else "jarvis"
        self._session_transcript.append(("user", "Ted", user_msg))
        reply_name = "Clawra" if persona == "clawra" else "JARVIS"
        reply_text = assistant_msg if isinstance(assistant_msg, str) else str(assistant_msg)
        self._session_transcript.append(("assistant", reply_name, reply_text))

    async def _save_session_transcript(self, persona: str) -> None:
        """Save accumulated transcript to memory/sessions/ and reset."""
        if not self.md_memory or not self._session_transcript:
            return

        try:
            # Build transcript markdown
            lines = []
            for role, name, text in self._session_transcript:
                lines.append(f"**{name}**: {text}")
            transcript = "\n".join(lines)

            # Generate slug from first user message
            first_user = next(
                (t for r, _, t in self._session_transcript if r == "user"), "chat"
            )
            slug = re.sub(r"[^\w]", "-", first_user[:30]).strip("-") or "chat"

            from datetime import datetime
            now = datetime.now()
            header = f"# {now.strftime('%Y-%m-%d %H:%M')} {slug}\n\n"
            self.md_memory.save_session(slug, header + transcript, date=now)
        except Exception as e:
            logger.debug(f"Failed to save session transcript: {e}")
        finally:
            self._session_transcript.clear()

    async def _memory_flush(self, persona: str, session_id: str) -> None:
        """G2: Flush important context to markdown memory before compression.

        Asks the LLM to extract key info from recent conversation,
        then saves preferences to MEMORY.md and progress to daily log.
        Silent â€” user does not see this process.
        """
        if not self.memos or not self.md_memory:
            return

        try:
            # Get recent conversation from MemOS
            history = await self.memos.get_conversation(
                session_id=session_id, limit=12,
            )
            if not history:
                return

            # Build conversation text for analysis
            conv_text = "\n".join(
                f"{e.get('role', '?')}: {e.get('content', '')}"
                for e in history
            )

            # Ask LLM to extract important info
            extract_prompt = (
                "å¾ä»¥ä¸‹å°è©±ä¸­æå–éœ€è¦é•·æœŸè¨˜ä½çš„é‡è¦è³‡è¨Šã€‚\n"
                "åˆ†å…©é¡è¼¸å‡ºï¼š\n"
                "PREF: ç”¨æˆ¶åå¥½æˆ–æŒ‡ä»¤ï¼ˆå¦‚ã€Œå–œæ­¡åƒæ‹‰éºµã€ã€Œä¸è¦ç”¨éŸ“æ–‡ã€ï¼‰\n"
                "PROG: ä»»å‹™é€²åº¦æˆ–è‡¨æ™‚æ±ºå®šï¼ˆå¦‚ã€Œå·²å®ŒæˆXXXã€ã€Œæ±ºå®šç”¨æ–¹æ¡ˆAã€ï¼‰\n"
                "ç´”é–’èŠä¸éœ€è¦è¼¸å‡ºã€‚æ¯è¡Œä¸€æ¢ï¼Œæ ¼å¼ï¼šPREF:xxx æˆ– PROG:xxx\n"
                "å¦‚æœæ²’æœ‰éœ€è¦è¨˜ä½çš„ï¼Œè¼¸å‡º NONE\n\n"
                f"å°è©±å…§å®¹ï¼š\n{conv_text[:2000]}"
            )

            response = await self.router.chat(
                [ChatMessage(role="user", content=extract_prompt)],
                role=ModelRole.CEO,
                task_type="template",
                max_tokens=200,
                temperature=0.1,
            )

            answer = response.content.strip()
            if answer == "NONE":
                return

            for line in answer.split("\n"):
                line = line.strip()
                if line.startswith("PREF:"):
                    self.md_memory.remember(line[5:].strip(), category="ç”¨æˆ¶åå¥½")
                elif line.startswith("PROG:"):
                    self.md_memory.log_daily(f"[flush] {line[5:].strip()}")

            logger.info("Memory flush completed (silent)")

        except Exception as e:
            logger.debug(f"Memory flush failed: {e}")

    # â”€â”€ Patch T+: Pre-compaction memory flush â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _pre_flush_extract(self, turns: list[dict]) -> None:
        """Extract important facts from turns about to be compressed.

        Called by ConversationCompressor before discarding old turns.
        Uses Lite model for cheap extraction, writes to daily memory.
        Fully guarded â€” failure only logs a warning.
        """
        if not self.md_memory or not turns:
            return

        try:
            # Build conversation snippet (first 200 chars per turn)
            lines = []
            for t in turns:
                role = t.get("role", "?")
                content = t.get("content", "")[:200]
                lines.append(f"{role}: {content}")
            conv_text = "\n".join(lines)

            prompt = (
                "å¾ä»¥ä¸‹å³å°‡è¢«å£“ç¸®çš„å°è©±ç‰‡æ®µä¸­ï¼Œæå–ä»»ä½•å€¼å¾—é•·æœŸè¨˜ä½çš„äº‹å¯¦ã€‚\n"
                "æ¯è¡Œä¸€æ¢ï¼Œç”¨ã€ŒFACT:ã€é–‹é ­ã€‚ç´”é–’èŠè¼¸å‡º NONEã€‚\n"
                "åªæå–ï¼šç”¨æˆ¶åå¥½ã€é‡è¦æ±ºå®šã€ä»»å‹™é€²åº¦ã€æ‰¿è«¾äº‹é …ã€‚\n\n"
                f"{conv_text[:3000]}"
            )

            response = await self.router.chat(
                [ChatMessage(role="user", content=prompt)],
                role=ModelRole.CEO,
                task_type="template",
                max_tokens=200,
                temperature=0.1,
            )

            answer = response.content.strip()
            if answer == "NONE" or not answer:
                return

            for line in answer.split("\n"):
                line = line.strip()
                if line.startswith("FACT:"):
                    fact = line[5:].strip()
                    if fact:
                        self.md_memory.log_daily(f"[pre-flush] {fact}")

            logger.info(f"Pre-flush extraction completed ({len(turns)} turns)")
        except Exception as e:
            logger.warning(f"Pre-flush extraction failed: {e}")

    # â”€â”€ Pending Selfie Management (Patch M) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    PENDING_SELFIE_PATH = Path("./data/pending_selfies.json")
    MAX_PENDING_SELFIES = 5

    def _save_pending_selfie(self, queue_info: dict) -> None:
        """Save a pending selfie for delayed checking by Heartbeat."""
        entries = self._load_pending_selfies()
        entries.append({
            "id": f"selfie_{int(time.time() * 1000)}",
            "status_url": queue_info["status_url"],
            "response_url": queue_info["response_url"],
            "persona": queue_info.get("persona", "clawra"),
            "created_at": time.time(),
            "status": "pending",
        })
        # Keep only latest MAX entries
        entries = entries[-self.MAX_PENDING_SELFIES:]
        self.PENDING_SELFIE_PATH.parent.mkdir(parents=True, exist_ok=True)
        self.PENDING_SELFIE_PATH.write_text(
            json.dumps(entries, ensure_ascii=False, indent=2), encoding="utf-8"
        )
        logger.info(f"Saved pending selfie for delayed check ({len(entries)} total)")

    def _load_pending_selfies(self) -> list[dict]:
        """Load pending selfies from JSON file."""
        if not self.PENDING_SELFIE_PATH.exists():
            return []
        try:
            return json.loads(self.PENDING_SELFIE_PATH.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            return []

    @staticmethod
    def _record_token_usage(response: ChatResponse) -> None:
        """Record token usage for model pool balancing."""
        try:
            from core.model_balancer import record_usage
            model = response.model
            usage = response.usage
            total = usage.get("total_tokens", 0)
            if not total:
                # Estimate from content length
                total = int(len(response.content) * 1.5) + 200
            record_usage(model, total)
        except Exception:
            pass  # non-critical
